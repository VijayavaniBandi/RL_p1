{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIsLdwBTXPKct26o7SZJXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayavaniBandi/RL_p1/blob/main/RL_p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1wFmNm6CBn_N"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab import drive, widgets\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "mIJrxmL0Bv5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_DIR = \"/content/drive/MyDrive/Assignment1/images\""
      ],
      "metadata": {
        "id": "Nyv7yfQ6Bv8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TIMESTEP = 10\n",
        "MAZE_WIDTH = 4\n",
        "MAZE_LENGTH = 4\n",
        "NUM_ACTIONS = 4\n",
        "NUM_STATES = MAZE_WIDTH * MAZE_LENGTH"
      ],
      "metadata": {
        "id": "-MmzWWlRBv-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_POS = np.asarray([3, 0])\n",
        "FINISH_POS = np.asarray([0, 3])\n",
        "GOLD_POS = np.asarray([0, 0])\n",
        "SILVER_POS = np.asarray([3, 3])\n",
        "OBSTACLE_POS = np.asarray([[2, 0], [1, 2], [1, 3], [3, 2]])"
      ],
      "metadata": {
        "id": "6KpBRU5MBwA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAZE = np.zeros((MAZE_WIDTH, MAZE_LENGTH))\n",
        "MAZE[tuple(START_POS)] = 2\n",
        "MAZE[tuple(FINISH_POS)] = 3\n",
        "MAZE[tuple(SILVER_POS)] = 4\n",
        "MAZE[tuple(GOLD_POS)] = 5\n",
        "for i in range(len(OBSTACLE_POS)):\n",
        "    MAZE[tuple(OBSTACLE_POS[i])] = -1"
      ],
      "metadata": {
        "id": "QmFOcv4jBwDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DICT = {-1: 'obstacle.png', 0: 'path.png', 1: 'agent.png', 2: 'start.png',\n",
        "              3: 'finish.png', 4: 'silver.png', 5: 'gold.png', \n",
        "              9: 'agent_obstacle.png', 12: 'agent_start.png', \n",
        "              13: 'agent_finish.png', 14: 'agent_silver.png', \n",
        "              15: 'agent_gold.png'}"
      ],
      "metadata": {
        "id": "QgmGo8K3BwF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_reshape(img):\n",
        "    img = Image.open(os.path.join(IMAGES_DIR, img)).convert('RGB')\n",
        "    img = img.resize((200, 200))\n",
        "    img = np.asarray(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "def maze_generator(maze):\n",
        "    img_arr = []\n",
        "    for state in maze:\n",
        "        img_arr.append(img_reshape(f\"{IMAGE_DICT[state]}\"))\n",
        "    array = np.array(img_arr)\n",
        "    index, height, width, channels = array.shape\n",
        "    img_grid = array.reshape(MAZE_WIDTH, MAZE_LENGTH, height, width, channels) \\\n",
        "                .swapaxes(1, 2).reshape(height * MAZE_WIDTH, \n",
        "                                        width * MAZE_LENGTH, channels)\n",
        "    return img_grid"
      ],
      "metadata": {
        "id": "nizTh1VnBwJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeDeterministicEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Creating the following custom maze as environment.\n",
        "    [5, 0, 0, 3,\n",
        "    0, 0, -1, -1,\n",
        "    -1, 0, 0, 0,\n",
        "    2, 0, -1, 4]\n",
        "\n",
        "    ### Description\n",
        "    -> 0 represents a valid position for an agent\n",
        "    -> -1 represents an obstacle\n",
        "    -> 2 represents the start point\n",
        "    -> 3 represents the finish point\n",
        "    -> 4 represents silver\n",
        "    -> 5 represents gold\n",
        "\n",
        "    ### Action Space\n",
        "    -> 0 represents moving up (North)\n",
        "    -> 1 represents moving right (East)\n",
        "    -> 2 represents moving down (South)\n",
        "    -> 3 represents moving left (West)\n",
        "\n",
        "    ### Reward\n",
        "    -> 10 for reaching the finish line\n",
        "    -> 4 for collecting gold\n",
        "    -> 2 for collecting silver\n",
        "    -> -5 for running into an obstacle\n",
        "    -> -0.5 for any other step\n",
        "\n",
        "    ### Motivation for the values\n",
        "    -> The agent should be able to reach finish line, maximising the points it\n",
        "      earns. With the given values, Collecting silver is not beneficial at all.\n",
        "    \"\"\" \n",
        "    metadata = {\"render_modes\": ['human']}\n",
        "\n",
        "    def __init__(self, env_type=None):\n",
        "        self.observation_space = spaces.Discrete(NUM_STATES)\n",
        "        self.action_space = spaces.Discrete(NUM_ACTIONS)\n",
        "\n",
        "        self.maze = MAZE.copy()\n",
        "        self.timestep = 0\n",
        "        self.gold_qty = 1\n",
        "        self.silver_qty = 1\n",
        "        self.agent_pos = START_POS.copy()\n",
        "\n",
        "    def reset(self):\n",
        "        self.timestep = 0\n",
        "        self.agent_pos = START_POS.copy()\n",
        "        self.gold_qty = 1\n",
        "        self.silver_qty = 1\n",
        "        return self._get_state(self.agent_pos)\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action)\n",
        "        self.timestep += 1\n",
        "\n",
        "        if action == 0 and self.agent_pos[0] > 0:\n",
        "            self.agent_pos[0] -= 1\n",
        "        elif action == 1 and self.agent_pos[1] < 3:\n",
        "            self.agent_pos[1] += 1\n",
        "        elif action == 2 and self.agent_pos[0] < 3:\n",
        "            self.agent_pos[0] += 1\n",
        "        elif action == 3 and self.agent_pos[1] > 0:\n",
        "            self.agent_pos[1] -= 1\n",
        "\n",
        "        self.maze = MAZE.copy()\n",
        "        done = False\n",
        "        if np.array_equal(self.agent_pos, FINISH_POS):\n",
        "            reward = 10\n",
        "            done = True\n",
        "        elif any(np.array_equal(OBSTACLE_POS[i], self.agent_pos) for i in \n",
        "                 range(len(OBSTACLE_POS))):\n",
        "            reward = -10\n",
        "        elif np.array_equal(self.agent_pos, SILVER_POS) and self.silver_qty > 0:\n",
        "            reward = 2\n",
        "            self.silver_qty = 0\n",
        "        elif np.array_equal(self.agent_pos, GOLD_POS) and self.gold_qty > 0:\n",
        "            reward = 4\n",
        "            self.gold_qty = 0\n",
        "        else:\n",
        "            reward = -0.5\n",
        "\n",
        "        if self.timestep >= MAX_TIMESTEP:\n",
        "            done = True\n",
        "\n",
        "        info = {}\n",
        "        return self._get_state(self.agent_pos), reward, done, info\n",
        "\n",
        "    def _get_state(self, agent_pos):\n",
        "        return agent_pos[0] * MAZE_LENGTH + agent_pos[1]\n",
        "\n",
        "    def render(self):\n",
        "        if self.gold_qty == 0:\n",
        "            self.maze[tuple(GOLD_POS)] = 0\n",
        "        if self.silver_qty == 0:\n",
        "            self.maze[tuple(SILVER_POS)] = 0\n",
        "        self.maze[tuple(self.agent_pos)] += 10\n",
        "        if self.maze[tuple(self.agent_pos)] % 10 == 0:\n",
        "            self.maze[tuple(self.agent_pos)] = 1\n",
        "        fig = plt.figure(figsize=(8., 8.))\n",
        "        plt.imshow(Grid_world_image_gen(self.maze.ravel()))"
      ],
      "metadata": {
        "id": "7hnpr089G1vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeStochasticEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Creating the following custom maze as environment.\n",
        "    [5, 0, 0, 3,\n",
        "    0, 0, -1, -1,\n",
        "    -1, 0, 0, 0,\n",
        "    2, 0, -1, 4]\n",
        "\n",
        "    ### Description\n",
        "    -> 0 represents a valid position for an agent\n",
        "    -> -1 represents an obstacle\n",
        "    -> 2 represents the start point\n",
        "    -> 3 represents the finish point\n",
        "    -> 4 represents silver\n",
        "    -> 5 represents gold\n",
        "\n",
        "    ### Action Space\n",
        "    -> 0 represents moving up (North)\n",
        "    -> 1 represents moving right (East)\n",
        "    -> 2 represents moving down (South)\n",
        "    -> 3 represents moving left (West)\n",
        "\n",
        "    ### Reward\n",
        "    -> 10 for reaching the finish line\n",
        "    -> 4 for collecting gold\n",
        "    -> 2 for collecting silver\n",
        "    -> -5 for running into an obstacle\n",
        "    -> -0.5 for any other step\n",
        "\n",
        "    ### Motivation for the values\n",
        "    -> The agent should be able to reach finish line, maximising the points it\n",
        "      earns. With the given values, Collecting silver is not beneficial at all.\n",
        "    \"\"\" \n",
        "    metadata = {\"render_modes\": ['human']}\n",
        "\n",
        "    def __init__(self, env_type=None):\n",
        "        self.observation_space = spaces.Discrete(NUM_STATES)\n",
        "        self.action_space = spaces.Discrete(NUM_ACTIONS)\n",
        "\n",
        "        self.maze = MAZE.copy()\n",
        "        self.timestep = 0\n",
        "        self.gold_qty = 1\n",
        "        self.silver_qty = 1\n",
        "        self.agent_pos = START_POS.copy()\n",
        "\n",
        "    def reset(self):\n",
        "        self.timestep = 0\n",
        "        self.agent_pos = START_POS.copy()\n",
        "        self.gold_qty = 1\n",
        "        self.silver_qty = 1\n",
        "        return self._get_state(self.agent_pos)\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action)\n",
        "        self.timestep += 1\n",
        "\n",
        "        alternate_action = [act for act in range(self.action_space.n) \n",
        "                              if act != action]\n",
        "        action = action if np.random.uniform() > 0.25 \\\n",
        "                          else np.random.choice(alternate_action)\n",
        "\n",
        "        if action == 0 and self.agent_pos[0] > 0:\n",
        "            self.agent_pos[0] -= 1\n",
        "        elif action == 1 and self.agent_pos[1] < 3:\n",
        "            self.agent_pos[1] += 1\n",
        "        elif action == 2 and self.agent_pos[0] < 3:\n",
        "            self.agent_pos[0] += 1\n",
        "        elif action == 3 and self.agent_pos[1] > 0:\n",
        "            self.agent_pos[1] -= 1\n",
        "\n",
        "        self.maze = MAZE.copy()\n",
        "        done = False\n",
        "        if np.array_equal(self.agent_pos, FINISH_POS):\n",
        "            reward = 10\n",
        "            done = True\n",
        "        elif any(np.array_equal(OBSTACLE_POS[i], self.agent_pos) for i in \n",
        "                 range(len(OBSTACLE_POS))):\n",
        "            reward = -10\n",
        "        elif np.array_equal(self.agent_pos, SILVER_POS) and self.silver_qty > 0:\n",
        "            reward = 2\n",
        "            self.silver_qty = 0\n",
        "        elif np.array_equal(self.agent_pos, GOLD_POS) and self.gold_qty > 0:\n",
        "            reward = 4\n",
        "            self.gold_qty = 0\n",
        "        else:\n",
        "            reward = -0.5\n",
        "\n",
        "        if self.timestep >= MAX_TIMESTEP:\n",
        "            done = True\n",
        "\n",
        "        info = {}\n",
        "        return self._get_state(self.agent_pos), reward, done, info\n",
        "\n",
        "    def _get_state(self, agent_pos):\n",
        "        return agent_pos[0] * MAZE_LENGTH + agent_pos[1]\n",
        "\n",
        "    def render(self):\n",
        "        if self.gold_qty == 0:\n",
        "            self.maze[tuple(GOLD_POS)] = 0\n",
        "        if self.silver_qty == 0:\n",
        "            self.maze[tuple(SILVER_POS)] = 0\n",
        "        self.maze[tuple(self.agent_pos)] += 10\n",
        "        if self.maze[tuple(self.agent_pos)] % 10 == 0:\n",
        "            self.maze[tuple(self.agent_pos)] = 1\n",
        "        fig = plt.figure(figsize=(8., 8.))\n",
        "        plt.imshow(Grid_world_image_gen(self.maze.ravel()))"
      ],
      "metadata": {
        "id": "MjnGjpgCG7s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAgent:\n",
        "  def __init__(self, env):\n",
        "    self.env = env\n",
        "    self.observation_space = env.observation_space\n",
        "    self.action_space = env.action_space\n",
        "\n",
        "  def step(self, pos):\n",
        "    return np.random.choice(self.action_space.n)"
      ],
      "metadata": {
        "id": "dKJXu_BhG7_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sik817LHTtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ux336xwiHT1h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}